{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy, time\n",
    "import argparse\n",
    "from datasets import EarlyStopScheduler, FaceImageDataset, FaceLoadImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet34WOmax import ResNet, BasicBlock, test_model\n",
    "resnet34 = ResNet([3, 4, 6, 3],BasicBlock , num_classes=4000, kernel_size = 3)\n",
    "model = resnet34\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "model = torch.load(\"./modelfcmore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:38<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  1.2707732170820236\n",
      "Testing Accuracy:  74.775 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "norm_transform = transforms.Compose([transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "val_data_root = \"./val_data\"\n",
    "valset = FaceLoadImageDataset(val_data_root, \"data/val\", transform=norm_transform)\n",
    "test_loader = DataLoader(valset, batch_size=256, shuffle=False, num_workers=8, drop_last=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_acc = test_model(model.to(device), test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the classification result with id label\n",
    "* we need to transform the class back to the id usung the target dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [07:56<00:00, 16.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import FaceImageDatasetEvl\n",
    "\n",
    "evl_set = FaceImageDatasetEvl(\"./test_data\", target_dict = valset.target_dict)\n",
    "eval_loader = DataLoader(evl_set, batch_size=1, shuffle=False, num_workers=8, drop_last=False)\n",
    "\n",
    "def find_key(dictionary,value):\n",
    "    for k, v in dictionary.items():  # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "        if v == value:\n",
    "            return k\n",
    "\n",
    "write_list = [] \n",
    "for batch_idx, (data, idx) in enumerate(tqdm.tqdm(eval_loader)):   \n",
    "    data = data.to(device)\n",
    "\n",
    "    outputs = model(data)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    out_label = find_key(evl_set.target_dict,predicted.item())\n",
    "    \n",
    "    write_list.append((idx[0],out_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resnorm.csv\", \"ab\") as f:\n",
    "    np.savetxt(f, [('id','label')], delimiter=',', fmt='%s')\n",
    "\n",
    "    for idx, target in write_list:\n",
    "        np.savetxt(f, [(idx,target)], delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verification\n",
    "Calculate the cosine similarity of the image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceImageDatasetVerification(Dataset):\n",
    "    def __init__(self, pairs_val, test = False):\n",
    "        \n",
    "        self.pairs_val = pairs_val\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs_val)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path1 = self.pairs_val[index][0]\n",
    "        img1 = Image.open(path1)\n",
    "        img1 = torchvision.transforms.ToTensor()(img1)\n",
    "        \n",
    "        path2 = self.pairs_val[index][1]\n",
    "        img2 = Image.open(path2)\n",
    "        img2 = torchvision.transforms.ToTensor()(img2)\n",
    "        \n",
    "        if self.test:\n",
    "            return img1, img2, path1, path2\n",
    "        else:\n",
    "            idx = self.pairs_val[index][2]\n",
    "            return img1, img2, path1, path2, idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"./verification_pairs_val.txt\", \"r\") as f:\n",
    "    verification_pairs_val = f.read().split(\"\\n\")\n",
    "ver_pairs_val = [l.split() for l in verification_pairs_val if l] ## last element will be an empty set due to  the \\n\n",
    "\n",
    "with open(\"./verification_pairs_test.txt\", \"r\") as f:\n",
    "    verification_pairs_test = f.read().split(\"\\n\")\n",
    "ver_pairs_test = [l.split() for l in verification_pairs_test if l] ## last element will be an empty set due to  the \\n\n",
    "\n",
    "vervalset = FaceImageDatasetVerification(ver_pairs_val, test=False)\n",
    "verification_val_loader = DataLoader(vervalset, batch_size=16, shuffle=False, num_workers=8, drop_last=False)\n",
    "\n",
    "vertestset = FaceImageDatasetVerification(ver_pairs_test, test=True)\n",
    "verification_test_loader = DataLoader(vertestset, batch_size=16, shuffle=False, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3240/3240 [31:29<00:00,  1.71it/s]  \n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "path_list = []\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "for img1,img2,path1,path2 in tqdm.tqdm(verification_test_loader):\n",
    "\n",
    "    embed1 = model.verification(img1.to(device))\n",
    "    embed2 = model.verification(img2.to(device))\n",
    "    \n",
    "    output = cos(embed1, embed2)\n",
    "    scores.append(output.cpu().detach().numpy())\n",
    "    path_list.append(np.array((path1,path2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1_list = [path[0] for path in path_list]\n",
    "path2_list = [path[1] for path in path_list]\n",
    "scores = np.concatenate(scores)\n",
    "path1_array = np.concatenate(path1_list)\n",
    "path2_array = np.concatenate(path2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resverification.csv\", \"ab\") as f:\n",
    "    np.savetxt(f, [('id','Category')], delimiter=',', fmt='%s')\n",
    "\n",
    "    for path1, path2, score in zip(path1_array,path2_array,scores):\n",
    "        np.savetxt(f, [(path1 + \" \" +path2, score)], delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 512/551 [05:02<00:08,  4.61it/s]"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "path_list = []\n",
    "true_labels = []\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "for img1,img2,path1,path2,label in tqdm.tqdm(verification_val_loader):\n",
    "\n",
    "    embed1 = model.verification(img1.to(device))\n",
    "    embed2 = model.verification(img2.to(device))\n",
    "    \n",
    "    output = cos(embed1, embed2)\n",
    "    scores.append(output.cpu().detach().numpy())\n",
    "    true_labels.append(label)\n",
    "    path_list.append(np.array((path1,path2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1_list = [path[0] for path in path_list]\n",
    "path2_list = [path[1] for path in path_list]\n",
    "scores = np.concatenate(scores)\n",
    "path1_array = np.concatenate(path1_list)\n",
    "path2_array = np.concatenate(path2_list)\n",
    "true_labels = np.concatenate(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(true_labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
